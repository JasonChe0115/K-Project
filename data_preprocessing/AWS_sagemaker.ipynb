{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dc233fd",
      "metadata": {
        "id": "3dc233fd"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import io\n",
        "import pandas as pd\n",
        "from sagemaker import get_execution_role\n",
        "from sagemaker.sklearn.processing import SKLearnProcessor\n",
        "from sagemaker.processing import ProcessingInput, ProcessingOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e7a50f9",
      "metadata": {
        "id": "6e7a50f9"
      },
      "outputs": [],
      "source": [
        "region = boto3.session.Session().region_name\n",
        "role = get_execution_role()\n",
        "\n",
        "sklearn_processor = SKLearnProcessor(\n",
        "    framework_version=\"0.20.0\",\n",
        "    role=role,\n",
        "    instance_type=\"ml.m5.large\",  \n",
        "    instance_count=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bef4e8e3",
      "metadata": {
        "id": "bef4e8e3",
        "outputId": "a9f53d07-68f9-4cc6-f249-bc74528c9040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting preprocessing.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile preprocessing.py\n",
        "\n",
        "import os\n",
        "\n",
        "os.system('pip install talib-binary')\n",
        "os.system('pip install seaborn')\n",
        "os.system('pip install backtrader')\n",
        "os.system('pip install backtesting')\n",
        "os.system('pip install deap')\n",
        "os.system('pip install IPython')\n",
        "\n",
        "import argparse\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "import talib\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "import logging\n",
        "import seaborn as sns\n",
        "from tqdm import trange\n",
        "import backtrader as bt\n",
        "import matplotlib.pyplot as plt\n",
        "from backtesting import Strategy\n",
        "from backtesting import Backtest\n",
        "import backtrader.feeds as btfeeds\n",
        "from IPython.display import display, Image\n",
        "from datetime import datetime, date, timedelta\n",
        "from deap import base, creator, tools, algorithms\n",
        "\n",
        "\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
        "\n",
        "class SmaCross1(bt.Strategy):\n",
        "  params = dict(\n",
        "    pfast=50, # period for the fast moving average\n",
        "    pslow=200 # period for the slow moving average \n",
        "    ) \n",
        "  \n",
        "  def __init__(self):\n",
        "    sma1 = bt.ind.SMA(period = self.p.pfast) # fast moving average \n",
        "    sma2 = bt.ind.SMA(period = self.p.pslow) # slow moving average \n",
        "    self.crossover = bt.ind.CrossOver(sma1, sma2) # crossover signal \n",
        "\n",
        "  def next(self): \n",
        "    if not self.position: # not in the market \n",
        "      if self.crossover > 0: # if fast crosses slow to the upside \n",
        "        close = self.data.close[0] # 종가 값 \n",
        "          \n",
        "        size = int(self.broker.getcash() / close) # 최대 구매 가능 개수 \n",
        "        self.buy(size=size) # 매수 size = 구매 개수 설정 \n",
        "    elif self.crossover < 0: # in the market & cross to the downside \n",
        "        self.close() # 매도\n",
        "\n",
        "class RSI(bt.Strategy):\n",
        "  params = dict(period=26)\n",
        "\n",
        "  def __init__(self):\n",
        "    self.rsi = bt.indicators.RSI(self.data.close, period=self.p.period)\n",
        "\n",
        "  def next(self):    \n",
        "    if not self.position:  #아직 주식을 사지 않았다면\n",
        "\n",
        "      if self.rsi <30 :\n",
        "        self.order = self.buy()\n",
        "\n",
        "    elif self. rsi >70 :\n",
        "      self.order = self.sell()\n",
        "\n",
        "class ROC(bt.Strategy):\n",
        "  params = dict(period=14)\n",
        "\n",
        "  def __init__(self):\n",
        "    self.roc = bt.indicators.ROC(self.data.close, period=self.p.period)\n",
        "\n",
        "  def next(self):    \n",
        "    if not self.position:  #아직 주식을 사지 않았다면\n",
        "\n",
        "      if self.roc > 0:\n",
        "        self.order = self.buy()\n",
        "\n",
        "    elif self.roc < 0:\n",
        "      self.order = self.sell()\n",
        "\n",
        "class MAP(bt.Strategy):\n",
        "  params = dict(period = 12, upperLimit = .07, lowerLimit = .07)\n",
        "\n",
        "  def __init__(self):\n",
        "    # self.sma = bt.ind.SMA(self.data.close, period = self.p.period) # fast moving average \n",
        "    self.sma = bt.ind.SMA(period = self.p.period)\n",
        "    self.ul = self.sma + (self.p.upperLimit * self.sma)\n",
        "    self.ll = self.sma + (self.p.lowerLimit * self.sma)\n",
        "\n",
        "  def next(self): \n",
        "    if not self.position: # 아직 주식을 사지 않았다면\n",
        "      if self.sma <= self.ll:\n",
        "        close = self.data.close[0] # 종가 값             \n",
        "        size = int(self.broker.getcash() / close) # 최대 구매 가능 개수 \n",
        "        self.buy(size=size) # 매수 size = 구매 개수 설정 \n",
        "\n",
        "    elif self.sma > self.ul:\n",
        "        self.sell() # 매도lf.sell() # 매도\n",
        "\n",
        "class StochasticSR(bt.Strategy):\n",
        "    '''Trading strategy that utilizes the Stochastic Oscillator indicator for oversold/overbought entry points, \n",
        "    and previous support/resistance via Donchian Channels as well as a max loss in pips for risk levels.'''\n",
        "    # parameters for Stochastic Oscillator and max loss in pips\n",
        "    # Donchian Channels to determine previous support/resistance levels will use the given period as well\n",
        "    # http://www.ta-guru.com/Book/TechnicalAnalysis/TechnicalIndicators/Stochastic.php5 for Stochastic Oscillator formula and description\n",
        "    params = (('period', 14), ('pfast', 3), ('pslow', 3), ('upperLimit', 80), ('lowerLimit', 20), ('stop_pips', .002))\n",
        "\n",
        "    def __init__(self):\n",
        "        '''Initializes logger and variables required for the strategy implementation.'''\n",
        "        # initialize logger for log function (set to critical to prevent any unwanted autologs, not using log objects because only care about logging one thing)\n",
        "        for handler in logging.root.handlers[:]:\n",
        "            logging.root.removeHandler(handler)\n",
        "\n",
        "        logging.basicConfig(format='%(message)s', level=logging.CRITICAL, handlers=[\n",
        "            logging.FileHandler(\"LOG.log\"),\n",
        "            logging.StreamHandler()\n",
        "            ])\n",
        "\n",
        "        self.order = None\n",
        "        self.donchian_stop_price = None\n",
        "        self.price = None\n",
        "        self.stop_price = None\n",
        "        self.stop_donchian = None\n",
        "\n",
        "        self.stochastic = bt.indicators.Stochastic(self.data, period=self.params.period, period_dfast=self.params.pfast, period_dslow=self.params.pslow, \n",
        "        upperband=self.params.upperLimit, lowerband=self.params.lowerLimit)\n",
        "\n",
        "\n",
        "    def next(self):\n",
        "        '''Checks to see if Stochastic Oscillator, position, and order conditions meet the entry or exit conditions for the execution of buy and sell orders.'''\n",
        "        if self.order:\n",
        "            # if there is a pending order, don't do anything\n",
        "            return\n",
        "        if self.position.size == 0:\n",
        "            # When stochastic crosses back below 80, enter short position.\n",
        "            if self.stochastic.lines.percD[-1] >= 80 and self.stochastic.lines.percD[0] <= 80:\n",
        "                # stop price at last support level in self.params.period periods\n",
        "                self.donchian_stop_price = max(self.data.high.get(size=self.params.period))\n",
        "                self.order = self.sell()\n",
        "                # stop loss order for max loss of self.params.stop_pips pips\n",
        "                self.stop_price = self.buy(exectype=bt.Order.Stop, price=self.data.close[0]+self.params.stop_pips, oco=self.stop_donchian)\n",
        "                # stop loss order for donchian SR price level\n",
        "                self.stop_donchian = self.buy(exectype=bt.Order.Stop, price=self.donchian_stop_price, oco=self.stop_price)\n",
        "            # when stochastic crosses back above 20, enter long position.\n",
        "            elif self.stochastic.lines.percD[-1] <= 20 and self.stochastic.lines.percD[0] >= 20:\n",
        "                # stop price at last resistance level in self.params.period periods\n",
        "                self.donchian_stop_price = min(self.data.low.get(size=self.params.period))\n",
        "                self.order = self.buy()\n",
        "                # stop loss order for max loss of self.params.stop_pips pips\n",
        "                self.stop_price = self.sell(exectype=bt.Order.Stop, price=self.data.close[0]-self.params.stop_pips, oco=self.stop_donchian)\n",
        "                # stop loss order for donchian SR price level\n",
        "                self.stop_donchian = self.sell(exectype=bt.Order.Stop, price=self.donchian_stop_price, oco=self.stop_price) \n",
        "  \n",
        "        if self.position.size > 0:\n",
        "            # When stochastic is above 70, close out of long position\n",
        "            if (self.stochastic.lines.percD[0] >= 70):\n",
        "                self.close(oco=self.stop_price)\n",
        "        if self.position.size < 0:\n",
        "            # When stochastic is below 30, close out of short position\n",
        "            if (self.stochastic.lines.percD[0] <= 30):\n",
        "                self.close(oco=self.stop_price)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    #parser.add_argument(\"--train-test-split-ratio\", type=float, default=0.3)\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    print(\"Received arguments {}\".format(args))\n",
        "    files = glob('/opt/ml/processing/input/*.csv')\n",
        "    \n",
        "    \n",
        "    print(\"각 인스턴스 처리하는 파일 개수 : \", len(files))\n",
        "    \n",
        "    \n",
        "    \n",
        "    for k, f in enumerate(files[:1]):\n",
        "\n",
        "        code = f[25:]\n",
        "        df = pd.read_csv(f)\n",
        "        #df = pd.read_csv(f)\n",
        "        #df = df[['TRD_DD','MKTCAP']] #날짜, 시가총액 열만 추출 \n",
        "        \n",
        "        #시간순 재정렬\n",
        "        df = df.sort_values(by=['TRD_DD'])\n",
        "        df.reset_index(drop=True,inplace=True)\n",
        "        df['TRD_DD'] = pd.to_datetime(df['TRD_DD']) #datetime변환\n",
        "\n",
        "        #인풋 데이터 모양 맞춰주기(backtest에 들어갈 데이터 모양)\n",
        "        df_bt = df[['TRD_DD','TDD_OPNPRC','TDD_HGPRC','TDD_LWPRC','TDD_CLSPRC', 'ACC_TRDVOL']]\n",
        "        df_bt['TRD_DD'] = pd.to_datetime(df_bt['TRD_DD'])\n",
        "        df_bt.rename(columns={'TRD_DD':'Date', 'TDD_OPNPRC':'Open', 'TDD_HGPRC':'High','TDD_LWPRC':'Low','TDD_CLSPRC':'Close', 'ACC_TRDVOL':'Volume'}, inplace=True)\n",
        "        df_bt.set_index('Date',drop=True,inplace=True)\n",
        "\n",
        "        #데이터프레임 콤마(,) 제거 그리고 타입 소수로 변환\n",
        "        df_bt['Open'] = df_bt['Open'].str.replace(',','').astype('float')\n",
        "        df_bt['High'] = df_bt['High'].str.replace(',','').astype('float')\n",
        "        df_bt['Low'] = df_bt['Low'].str.replace(',','').astype('float')\n",
        "        df_bt['Close'] = df_bt['Close'].str.replace(',','').astype('float')\n",
        "        df_bt['Volume'] = df_bt['Volume'].str.replace(',','').astype('float')\n",
        "        \n",
        "        \n",
        "# GDC --------------------------------------------------------------------------\n",
        "\n",
        "        try:\n",
        "\n",
        "            random.seed(3)\n",
        "\n",
        "            PARAM_NAMES = [\"pfast\", \"pslow\"]\n",
        "\n",
        "            NGEN = 5  # 알고리즘 5번 반복.\n",
        "            NPOP = 100 #인구 초기\n",
        "            CXPB = 0.5  #교차 전략 \n",
        "            MUTPB = 0.3  #돌연변이 전략.\n",
        "\n",
        "\n",
        "            #최소fintness 설정 (fitness값이 작을수록 좋도록 설정)\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "            creator.create('Individual', list, fitness=creator.FitnessMin)\n",
        "\n",
        "            # creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "            # creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "            def evaluate(individual, plot=False, log=False):\n",
        "\n",
        "              strategy_params = {k: v for k, v in zip(PARAM_NAMES, individual)}\n",
        "\n",
        "              cerebro = bt.Cerebro(stdstats=False)\n",
        "\n",
        "              data = bt.feeds.PandasData(dataname = df_bt)\n",
        "\n",
        "              cerebro.adddata(data)\n",
        "\n",
        "              initial_capital = 1000000\n",
        "              cerebro.broker.setcash(initial_capital)\n",
        "\n",
        "              cerebro.addstrategy(SmaCross1, **strategy_params)\n",
        "\n",
        "              cerebro.addanalyzer(bt.analyzers.DrawDown)\n",
        "\n",
        "              cerebro.broker.setcommission(commission=0.0025, margin=False)  #수수료 설정\n",
        "\n",
        "              strats = cerebro.run()\n",
        "\n",
        "              profit = cerebro.broker.getvalue() - initial_capital\n",
        "\n",
        "              if profit == 0:\n",
        "                return [np.inf]\n",
        "\n",
        "              # max_dd = strats[0].analyzers.drawdown.get_analysis()[\"max\"][\"moneydown\"] # max.moneydown - max drawdown value in monetary units\n",
        "              # fitness = profit / (max_dd if max_dd > 0 else 1)\n",
        "              fitness = round(1 / profit, 15)\n",
        "\n",
        "              if log:\n",
        "                print(f\"Starting Portfolio Value: {initial_capital:,.2f}\")\n",
        "                print(f\"Final Portfolio Value:  {cerebro.broker.getvalue():,.2f}\")\n",
        "                print(f\"Total Profit:       {profit:,.2f}\")\n",
        "                print(f\"Profit / Max DD:     {fitness}\")\n",
        "\n",
        "              # if plot:\n",
        "                # cerebro.plot()\n",
        "\n",
        "              return [fitness]\n",
        "\n",
        "            toolbox = base.Toolbox()\n",
        "            toolbox.register(\"indices\", random.sample, range(NPOP), NPOP)\n",
        "\n",
        "            # crossover strategy\n",
        "            toolbox.register(\"mate\", tools.cxUniform, indpb=CXPB)\n",
        "            # mutation strategy\n",
        "            toolbox.register(\"mutate\", tools.mutUniformInt, low=1, up=151, indpb=0.2)\n",
        "            # selection strategy\n",
        "            toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            # fitness function\n",
        "            toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "\n",
        "            # definition of an individual & a population\n",
        "            toolbox.register(\"attr_sma1\", random.randint, 1, 100)\n",
        "            toolbox.register(\"attr_sma2\", random.randint, 151, 251) \n",
        "            toolbox.register(\n",
        "              \"individual\",\n",
        "              tools.initCycle,\n",
        "              creator.Individual,\n",
        "              (\n",
        "                toolbox.attr_sma1,\n",
        "                toolbox.attr_sma2,\n",
        "\n",
        "              ),\n",
        "            )\n",
        "\n",
        "            toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "            mean = np.ndarray(NGEN)\n",
        "            best = np.ndarray(NGEN)\n",
        "            hall_of_fame = tools.HallOfFame(maxsize=3)\n",
        "\n",
        "            t = time.perf_counter()\n",
        "            pop = toolbox.population(n=NPOP)\n",
        "            for g in trange(NGEN):\n",
        "              # Select the next generation individuals\n",
        "              offspring = toolbox.select(pop, len(pop))\n",
        "              # Clone the selected individuals\n",
        "              offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "              # Apply crossover on the offspring\n",
        "              for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "                if random.random() < CXPB:\n",
        "                  toolbox.mate(child1, child2)\n",
        "                  del child1.fitness.values\n",
        "                  del child2.fitness.values\n",
        "\n",
        "              # Apply mutation on the offspring\n",
        "              for mutant in offspring:\n",
        "                if random.random() < MUTPB:\n",
        "                  toolbox.mutate(mutant)\n",
        "                  del mutant.fitness.values\n",
        "\n",
        "              # Evaluate the individuals with an invalid fitness\n",
        "              invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "              fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "              for ind, fit in zip(invalid_ind, fitnesses):\n",
        "                ind.fitness.values = fit\n",
        "\n",
        "              # The population is entirely replaced by the offspring\n",
        "              pop[:] = offspring\n",
        "              hall_of_fame.update(pop)\n",
        "              print(\n",
        "                \"\\n HALL OF FAME:\\n\"\n",
        "                + \"\\n\".join(\n",
        "                  [\n",
        "                    f\"  {_}: {ind}, Fitness: {ind.fitness.values[0]}\"\n",
        "                    for _, ind in enumerate(hall_of_fame)\n",
        "                  ]\n",
        "                )\n",
        "              )\n",
        "\n",
        "              fitnesses = [\n",
        "                ind.fitness.values[0] for ind in pop if not np.isinf(ind.fitness.values[0])\n",
        "              ]\n",
        "              mean[g] = np.mean(fitnesses)\n",
        "              best[g] = np.max(fitnesses)\n",
        "\n",
        "            end_t = time.perf_counter()\n",
        "            print(f\"Time Elapsed: {end_t - t:,.2f}\")\n",
        "\n",
        "            # 최적의 파라미터 값 출력\n",
        "            OPTIMISED_STRATEGY_PARAMS = {\n",
        "              k: v for k, v in zip(PARAM_NAMES, hall_of_fame[0])}\n",
        "            GDC_params = list(OPTIMISED_STRATEGY_PARAMS.values())\n",
        "            print('**GDC 파라미터 값: ', GDC_params)\n",
        "            print('\\n')                       \n",
        "            \n",
        "        except:\n",
        "            GDC_params = [50, 200]\n",
        "        \n",
        "        \n",
        "# RSI --------------------------------------------------------------------------\n",
        "\n",
        "        try:\n",
        "            random.seed(3)\n",
        "\n",
        "            PARAM_NAMES = [\"period\"]\n",
        "\n",
        "            NGEN = 5  # 알고리즘 5번 반복.\n",
        "            NPOP = 100 #인구 초기\n",
        "            CXPB = 0.5  #교차 전략 \n",
        "            MUTPB = 0.3  #돌연변이 전략.\n",
        "\n",
        "\n",
        "            #최소fintness 설정 (fitness값이 작을수록 좋도록 설정)\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "            creator.create('Individual', list, fitness=creator.FitnessMin)\n",
        "\n",
        "            # creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "            # creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "            def evaluate(individual, plot=False, log=False):\n",
        "\n",
        "              strategy_params = {k: v for k, v in zip(PARAM_NAMES, individual)}\n",
        "\n",
        "              cerebro = bt.Cerebro(stdstats=False)\n",
        "\n",
        "              data = bt.feeds.PandasData(dataname = df_bt)\n",
        "\n",
        "              cerebro.adddata(data)\n",
        "\n",
        "              initial_capital = 1000000\n",
        "              cerebro.broker.setcash(initial_capital)\n",
        "\n",
        "              cerebro.addstrategy(RSI, **strategy_params)\n",
        "\n",
        "              cerebro.addanalyzer(bt.analyzers.DrawDown)\n",
        "\n",
        "              cerebro.broker.setcommission(commission=0.0025, margin=False)  #수수료 설정\n",
        "\n",
        "              strats = cerebro.run()\n",
        "\n",
        "              profit = cerebro.broker.getvalue() - initial_capital\n",
        "\n",
        "              if profit == 0:\n",
        "                return [np.inf]\n",
        "\n",
        "              # max_dd = strats[0].analyzers.drawdown.get_analysis()[\"max\"][\"moneydown\"] # max.moneydown - max drawdown value in monetary units\n",
        "              # fitness = profit / (max_dd if max_dd > 0 else 1)\n",
        "              fitness = round(1 / profit, 15)\n",
        "\n",
        "              if log:\n",
        "                print(f\"Starting Portfolio Value: {initial_capital:,.2f}\")\n",
        "                print(f\"Final Portfolio Value:  {cerebro.broker.getvalue():,.2f}\")\n",
        "                print(f\"Total Profit:       {profit:,.2f}\")\n",
        "                print(f\"Profit / Max DD:     {fitness}\")\n",
        "\n",
        "              # if plot:\n",
        "                # cerebro.plot()\n",
        "\n",
        "              return [fitness]\n",
        "\n",
        "            toolbox = base.Toolbox()\n",
        "            toolbox.register(\"indices\", random.sample, range(NPOP), NPOP)\n",
        "\n",
        "            # crossover strategy\n",
        "            toolbox.register(\"mate\", tools.cxUniform, indpb=CXPB)\n",
        "            # mutation strategy\n",
        "            toolbox.register(\"mutate\", tools.mutUniformInt, low=1, up=151, indpb=0.2)\n",
        "            # selection strategy\n",
        "            toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            # fitness function\n",
        "            toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "\n",
        "            # definition of an individual & a population\n",
        "            toolbox.register(\"attr_period\", random.randint, 1, 100)\n",
        "            toolbox.register(\n",
        "              \"individual\",\n",
        "              tools.initCycle,\n",
        "              creator.Individual,\n",
        "              (\n",
        "                toolbox.attr_period,\n",
        "\n",
        "              ),\n",
        "            )\n",
        "\n",
        "            toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "            mean = np.ndarray(NGEN)\n",
        "            best = np.ndarray(NGEN)\n",
        "            hall_of_fame = tools.HallOfFame(maxsize=3)\n",
        "\n",
        "            t = time.perf_counter()\n",
        "            pop = toolbox.population(n=NPOP)\n",
        "            for g in trange(NGEN):\n",
        "              # Select the next generation individuals\n",
        "              offspring = toolbox.select(pop, len(pop))\n",
        "              # Clone the selected individuals\n",
        "              offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "              # Apply crossover on the offspring\n",
        "              for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "                if random.random() < CXPB:\n",
        "                  toolbox.mate(child1, child2)\n",
        "                  del child1.fitness.values\n",
        "                  del child2.fitness.values\n",
        "\n",
        "              # Apply mutation on the offspring\n",
        "              for mutant in offspring:\n",
        "                if random.random() < MUTPB:\n",
        "                  toolbox.mutate(mutant)\n",
        "                  del mutant.fitness.values\n",
        "\n",
        "              # Evaluate the individuals with an invalid fitness\n",
        "              invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "              fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "              for ind, fit in zip(invalid_ind, fitnesses):\n",
        "                ind.fitness.values = fit\n",
        "\n",
        "              # The population is entirely replaced by the offspring\n",
        "              pop[:] = offspring\n",
        "              hall_of_fame.update(pop)\n",
        "              print(\n",
        "                \"\\n HALL OF FAME:\\n\"\n",
        "                + \"\\n\".join(\n",
        "                  [\n",
        "                    f\"  {_}: {ind}, Fitness: {ind.fitness.values[0]}\"\n",
        "                    for _, ind in enumerate(hall_of_fame)\n",
        "                  ]\n",
        "                )\n",
        "              )\n",
        "\n",
        "              fitnesses = [\n",
        "                ind.fitness.values[0] for ind in pop if not np.isinf(ind.fitness.values[0])\n",
        "              ]\n",
        "              mean[g] = np.mean(fitnesses)\n",
        "              best[g] = np.max(fitnesses)\n",
        "\n",
        "            end_t = time.perf_counter()\n",
        "            print(f\"Time Elapsed: {end_t - t:,.2f}\")\n",
        "\n",
        "            # 최적의 파라미터 값 출력\n",
        "            OPTIMISED_STRATEGY_PARAMS = {\n",
        "              k: v for k, v in zip(PARAM_NAMES, hall_of_fame[0])}\n",
        "            RSI_params = list(OPTIMISED_STRATEGY_PARAMS.values())\n",
        "            print('RSI 파라미터 값: ', RSI_params)\n",
        "            print('\\n')\n",
        "\n",
        "\n",
        "        except:\n",
        "            RSI_params = [26]\n",
        "\n",
        "# ROC --------------------------------------------------------------------------\n",
        "\n",
        "        try:\n",
        "        \n",
        "            random.seed(3)\n",
        "\n",
        "            PARAM_NAMES = [\"period\"]\n",
        "\n",
        "            NGEN = 5  # 알고리즘 5번 반복.\n",
        "            NPOP = 100 #인구 초기\n",
        "            CXPB = 0.5  #교차 전략 \n",
        "            MUTPB = 0.3  #돌연변이 전략.\n",
        "\n",
        "\n",
        "            #최소fintness 설정 (fitness값이 작을수록 좋도록 설정)\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "            creator.create('Individual', list, fitness=creator.FitnessMin)\n",
        "\n",
        "            # creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "            # creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "            def evaluate(individual, plot=False, log=False):\n",
        "\n",
        "              strategy_params = {k: v for k, v in zip(PARAM_NAMES, individual)}\n",
        "\n",
        "              cerebro = bt.Cerebro(stdstats=False)\n",
        "\n",
        "              data = bt.feeds.PandasData(dataname = df_bt)\n",
        "\n",
        "              cerebro.adddata(data)\n",
        "\n",
        "              initial_capital = 1000000\n",
        "              cerebro.broker.setcash(initial_capital)\n",
        "\n",
        "              cerebro.addstrategy(ROC, **strategy_params)\n",
        "\n",
        "              cerebro.addanalyzer(bt.analyzers.DrawDown)\n",
        "\n",
        "              cerebro.broker.setcommission(commission=0.0025, margin=False)  #수수료 설정\n",
        "\n",
        "              strats = cerebro.run()\n",
        "\n",
        "              profit = cerebro.broker.getvalue() - initial_capital\n",
        "\n",
        "              if profit == 0:\n",
        "                return [np.inf]\n",
        "\n",
        "              # max_dd = strats[0].analyzers.drawdown.get_analysis()[\"max\"][\"moneydown\"] # max.moneydown - max drawdown value in monetary units\n",
        "              # fitness = profit / (max_dd if max_dd > 0 else 1)\n",
        "              fitness = round(1 / profit, 15)\n",
        "\n",
        "              if log:\n",
        "                print(f\"Starting Portfolio Value: {initial_capital:,.2f}\")\n",
        "                print(f\"Final Portfolio Value:  {cerebro.broker.getvalue():,.2f}\")\n",
        "                print(f\"Total Profit:       {profit:,.2f}\")\n",
        "                print(f\"Profit / Max DD:     {fitness}\")\n",
        "\n",
        "              # if plot:\n",
        "                # cerebro.plot()\n",
        "\n",
        "              return [fitness]\n",
        "\n",
        "            toolbox = base.Toolbox()\n",
        "            toolbox.register(\"indices\", random.sample, range(NPOP), NPOP)\n",
        "\n",
        "            # crossover strategy\n",
        "            toolbox.register(\"mate\", tools.cxUniform, indpb=CXPB)\n",
        "            # mutation strategy\n",
        "            toolbox.register(\"mutate\", tools.mutUniformInt, low=1, up=151, indpb=0.2)\n",
        "            # selection strategy\n",
        "            toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            # fitness function\n",
        "            toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "\n",
        "            # definition of an individual & a population\n",
        "            toolbox.register(\"attr_period\", random.randint, 1, 100)\n",
        "            toolbox.register(\n",
        "              \"individual\",\n",
        "              tools.initCycle,\n",
        "              creator.Individual,\n",
        "              (\n",
        "                toolbox.attr_period,\n",
        "\n",
        "              ),\n",
        "            )\n",
        "\n",
        "            toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "            mean = np.ndarray(NGEN)\n",
        "            best = np.ndarray(NGEN)\n",
        "            hall_of_fame = tools.HallOfFame(maxsize=3)\n",
        "\n",
        "            t = time.perf_counter()\n",
        "            pop = toolbox.population(n=NPOP)\n",
        "            for g in trange(NGEN):\n",
        "              # Select the next generation individuals\n",
        "              offspring = toolbox.select(pop, len(pop))\n",
        "              # Clone the selected individuals\n",
        "              offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "              # Apply crossover on the offspring\n",
        "              for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "                if random.random() < CXPB:\n",
        "                  toolbox.mate(child1, child2)\n",
        "                  del child1.fitness.values\n",
        "                  del child2.fitness.values\n",
        "\n",
        "              # Apply mutation on the offspring\n",
        "              for mutant in offspring:\n",
        "                if random.random() < MUTPB:\n",
        "                  toolbox.mutate(mutant)\n",
        "                  del mutant.fitness.values\n",
        "\n",
        "              # Evaluate the individuals with an invalid fitness\n",
        "              invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "              fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "              for ind, fit in zip(invalid_ind, fitnesses):\n",
        "                ind.fitness.values = fit\n",
        "\n",
        "              # The population is entirely replaced by the offspring\n",
        "              pop[:] = offspring\n",
        "              hall_of_fame.update(pop)\n",
        "              print(\n",
        "                \"\\n HALL OF FAME:\\n\"\n",
        "                + \"\\n\".join(\n",
        "                  [\n",
        "                    f\"  {_}: {ind}, Fitness: {ind.fitness.values[0]}\"\n",
        "                    for _, ind in enumerate(hall_of_fame)\n",
        "                  ]\n",
        "                )\n",
        "              )\n",
        "\n",
        "              fitnesses = [\n",
        "                ind.fitness.values[0] for ind in pop if not np.isinf(ind.fitness.values[0])\n",
        "              ]\n",
        "              mean[g] = np.mean(fitnesses)\n",
        "              best[g] = np.max(fitnesses)\n",
        "\n",
        "            end_t = time.perf_counter()\n",
        "            print(f\"Time Elapsed: {end_t - t:,.2f}\")\n",
        "\n",
        "            # 최적의 파라미터 값 출력\n",
        "            OPTIMISED_STRATEGY_PARAMS = {\n",
        "              k: v for k, v in zip(PARAM_NAMES, hall_of_fame[0])}\n",
        "            ROC_params = list(OPTIMISED_STRATEGY_PARAMS.values())\n",
        "            print('**ROC 파라미터 값: ', ROC_params)\n",
        "\n",
        "\n",
        "        except:\n",
        "            ROC_params = [14]\n",
        "\n",
        "# MAP --------------------------------------------------------------------------\n",
        "\n",
        "        try:\n",
        "            random.seed(3)\n",
        "\n",
        "            PARAM_NAMES = [\"period\", \"upperLimit\", \"lowerLimit\"]\n",
        "\n",
        "            NGEN = 5  # 알고리즘 5번 반복.\n",
        "            NPOP = 100 #인구 초기\n",
        "            CXPB = 0.5  #교차 전략 \n",
        "            MUTPB = 0.3  #돌연변이 전략.\n",
        "\n",
        "\n",
        "            #최소fintness 설정 (fitness값이 작을수록 좋도록 설정)\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "            creator.create('Individual', list, fitness=creator.FitnessMin)\n",
        "\n",
        "            # creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "            # creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "            def evaluate(individual, plot=False, log=False):\n",
        "\n",
        "              strategy_params = {k: v for k, v in zip(PARAM_NAMES, individual)}\n",
        "\n",
        "              cerebro = bt.Cerebro(stdstats=False)\n",
        "\n",
        "              data = bt.feeds.PandasData(dataname = df_bt)\n",
        "\n",
        "              cerebro.adddata(data)\n",
        "\n",
        "              initial_capital = 1000000\n",
        "              cerebro.broker.setcash(initial_capital)\n",
        "\n",
        "              cerebro.addstrategy(MAP, **strategy_params)\n",
        "\n",
        "              cerebro.addanalyzer(bt.analyzers.DrawDown)\n",
        "\n",
        "              cerebro.broker.setcommission(commission=0.0025, margin=False)  #수수료 설정\n",
        "\n",
        "              strats = cerebro.run()\n",
        "\n",
        "              #profit = cerebro.broker.getvalue() - initial_capital\n",
        "              profit = cerebro.broker.getvalue()\n",
        "\n",
        "              if profit == 0:\n",
        "                return [np.inf]\n",
        "              # max_dd = strats[0].analyzers.drawdown.get_analysis()[\"max\"][\"moneydown\"] # max.moneydown - max drawdown value in monetary units\n",
        "              # fitness = profit / (max_dd if max_dd > 0 else 1)\n",
        "              fitness = round(1 / profit, 15)\n",
        "\n",
        "              if log:\n",
        "                print(f\"Starting Portfolio Value: {initial_capital:,.2f}\")\n",
        "                print(f\"Final Portfolio Value:  {cerebro.broker.getvalue():,.2f}\")\n",
        "                print(f\"Total Profit:       {profit:,.2f}\")\n",
        "                print(f\"Profit / Max DD:     {fitness}\")\n",
        "\n",
        "              # if plot:\n",
        "                # cerebro.plot()\n",
        "\n",
        "              return [fitness]\n",
        "\n",
        "            toolbox = base.Toolbox()\n",
        "            toolbox.register(\"indices\", random.sample, range(NPOP), NPOP)\n",
        "\n",
        "            # crossover strategy\n",
        "            toolbox.register(\"mate\", tools.cxUniform, indpb=CXPB)\n",
        "            # mutation strategy\n",
        "            toolbox.register(\"mutate\", tools.mutUniformInt, low=1, up=151, indpb=0.2)\n",
        "            # selection strategy\n",
        "            toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            # fitness function\n",
        "            toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "\n",
        "            # definition of an individual & a population\n",
        "            toolbox.register(\"attr_period\", random.randint, 1, 100)\n",
        "            toolbox.register(\"attr_upperLimit\", random.uniform, 0.05, 0.09)\n",
        "            toolbox.register(\"attr_lowerLimit\", random.uniform, 0.05, 0.09)\n",
        "\n",
        "            toolbox.register(\n",
        "              \"individual\",\n",
        "              tools.initCycle,\n",
        "              creator.Individual,\n",
        "              (\n",
        "                toolbox.attr_period,\n",
        "                toolbox.attr_upperLimit,\n",
        "                toolbox.attr_lowerLimit,\n",
        "\n",
        "              ),\n",
        "            )\n",
        "\n",
        "            toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "            mean = np.ndarray(NGEN)\n",
        "            best = np.ndarray(NGEN)\n",
        "            hall_of_fame = tools.HallOfFame(maxsize=3)\n",
        "\n",
        "            t = time.perf_counter()\n",
        "            pop = toolbox.population(n=NPOP)\n",
        "            for g in trange(NGEN):\n",
        "              # Select the next generation individuals\n",
        "              offspring = toolbox.select(pop, len(pop))\n",
        "              # Clone the selected individuals\n",
        "              offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "              # Apply crossover on the offspring\n",
        "              for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "                if random.random() < CXPB:\n",
        "                  toolbox.mate(child1, child2)\n",
        "                  del child1.fitness.values\n",
        "                  del child2.fitness.values\n",
        "\n",
        "              # Apply mutation on the offspring\n",
        "              for mutant in offspring:\n",
        "                if random.random() < MUTPB:\n",
        "                  toolbox.mutate(mutant)\n",
        "                  del mutant.fitness.values\n",
        "\n",
        "              # Evaluate the individuals with an invalid fitness\n",
        "              invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "              fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "              for ind, fit in zip(invalid_ind, fitnesses):\n",
        "                ind.fitness.values = fit\n",
        "\n",
        "              # The population is entirely replaced by the offspring\n",
        "              pop[:] = offspring\n",
        "              hall_of_fame.update(pop)\n",
        "              print(\n",
        "                \"\\n HALL OF FAME:\\n\"\n",
        "                + \"\\n\".join(\n",
        "                  [\n",
        "                    f\"  {_}: {ind}, Fitness: {ind.fitness.values[0]}\"\n",
        "                    for _, ind in enumerate(hall_of_fame)\n",
        "                  ]\n",
        "                )\n",
        "              )\n",
        "\n",
        "              fitnesses = [\n",
        "                ind.fitness.values[0] for ind in pop if not np.isinf(ind.fitness.values[0])\n",
        "              ]\n",
        "              mean[g] = np.mean(fitnesses)\n",
        "              best[g] = np.max(fitnesses)\n",
        "\n",
        "            end_t = time.perf_counter()\n",
        "            print(f\"Time Elapsed: {end_t - t:,.2f}\")\n",
        "\n",
        "            # 최적의 파라미터 값 출력\n",
        "            OPTIMISED_STRATEGY_PARAMS = {\n",
        "              k: v for k, v in zip(PARAM_NAMES, hall_of_fame[0])}\n",
        "            MAP_params = list(OPTIMISED_STRATEGY_PARAMS.values())\n",
        "            print('**MAP 파라미터 값: ', MAP_params)\n",
        "\n",
        "\n",
        "        except:\n",
        "            MAP_params = [12, 0.07, 0.07]\n",
        "\n",
        "# STC --------------------------------------------------------------------------\n",
        "\n",
        "        try:\n",
        "        \n",
        "            random.seed(3)\n",
        "\n",
        "            PARAM_NAMES = [\"period\",\"pfast\",\"pslow\",\"upperLimit\",\"lowerLimit\"]\n",
        "\n",
        "            NGEN = 5  # 알고리즘 5번 반복.\n",
        "            NPOP = 100 #인구 초기\n",
        "            CXPB = 0.5  #교차 전략 \n",
        "            MUTPB = 0.3  #돌연변이 전략.\n",
        "\n",
        "\n",
        "            #최소fintness 설정 (fitness값이 작을수록 좋도록 설정)\n",
        "            creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "            creator.create('Individual', list, fitness=creator.FitnessMin)\n",
        "\n",
        "            # creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "            # creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "            def evaluate(individual, plot=False, log=False):\n",
        "\n",
        "              strategy_params = {k: v for k, v in zip(PARAM_NAMES, individual)}\n",
        "\n",
        "              cerebro = bt.Cerebro(stdstats=False)\n",
        "\n",
        "              data = bt.feeds.PandasData(dataname = df_bt, name = i)\n",
        "\n",
        "              cerebro.adddata(data)\n",
        "\n",
        "              initial_capital = 1000000\n",
        "              cerebro.broker.setcash(initial_capital)\n",
        "\n",
        "              cerebro.addstrategy(StochasticSR, **strategy_params)\n",
        "\n",
        "              cerebro.addanalyzer(bt.analyzers.DrawDown)\n",
        "\n",
        "              cerebro.broker.setcommission(commission=0.0025, margin=False)  #수수료 설정\n",
        "\n",
        "              strats = cerebro.run()\n",
        "\n",
        "              profit = cerebro.broker.getvalue() - initial_capital\n",
        "\n",
        "              # max_dd = strats[0].analyzers.drawdown.get_analysis()[\"max\"][\"moneydown\"] # max.moneydown - max drawdown value in monetary units\n",
        "              # fitness = profit / (max_dd if max_dd > 0 else 1)\n",
        "              fitness = round(1 / profit, 15)\n",
        "\n",
        "              if log:\n",
        "                print(f\"Starting Portfolio Value: {initial_capital:,.2f}\")\n",
        "                print(f\"Final Portfolio Value:  {cerebro.broker.getvalue():,.2f}\")\n",
        "                print(f\"Total Profit:       {profit:,.2f}\")\n",
        "                print(f\"Profit / Max DD:     {fitness}\")\n",
        "\n",
        "              # if plot:\n",
        "                # cerebro.plot()\n",
        "\n",
        "              return [fitness]\n",
        "\n",
        "            toolbox = base.Toolbox()\n",
        "            toolbox.register(\"indices\", random.sample, range(NPOP), NPOP)\n",
        "\n",
        "            # crossover strategy\n",
        "            toolbox.register(\"mate\", tools.cxUniform, indpb=CXPB)\n",
        "            # mutation strategy\n",
        "            toolbox.register(\"mutate\", tools.mutUniformInt, low=1, up=151, indpb=0.2)\n",
        "            # selection strategy\n",
        "            toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "            # fitness function\n",
        "            toolbox.register(\"evaluate\", evaluate)\n",
        "\n",
        "\n",
        "            # definition of an individual & a population\n",
        "            # 파라미터 개수 및 범위 설정 - toolbox.register\n",
        "            toolbox.register('attr_period', random.randint, 5, 31) \n",
        "            toolbox.register('attr_pfast', random.randint, 2, 21)\n",
        "            toolbox.register('attr_pslow', random.randint, 2, 21)\n",
        "            toolbox.register('attr_upperLimit', random.randint, 70, 91)\n",
        "            toolbox.register('attr_lowerLimit', random.randint, 10, 31)\n",
        "\n",
        "\n",
        "            toolbox.register(\n",
        "              \"individual\",\n",
        "              tools.initCycle,\n",
        "              creator.Individual,\n",
        "              (   # 파라미터 개수 설정\n",
        "                  toolbox.attr_period,\n",
        "                  toolbox.attr_pfast,\n",
        "                  toolbox.attr_pslow,\n",
        "                  toolbox.attr_upperLimit,\n",
        "                  toolbox.attr_lowerLimit,\n",
        "              ),\n",
        "            )\n",
        "\n",
        "            toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "            mean = np.ndarray(NGEN)\n",
        "            best = np.ndarray(NGEN)\n",
        "            hall_of_fame = tools.HallOfFame(maxsize=3)\n",
        "\n",
        "            t = time.perf_counter()\n",
        "            pop = toolbox.population(n=NPOP)\n",
        "            for g in trange(NGEN):\n",
        "              # Select the next generation individuals\n",
        "              offspring = toolbox.select(pop, len(pop))\n",
        "              # Clone the selected individuals\n",
        "              offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "              # Apply crossover on the offspring\n",
        "              for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
        "                if random.random() < CXPB:\n",
        "                  toolbox.mate(child1, child2)\n",
        "                  del child1.fitness.values\n",
        "                  del child2.fitness.values\n",
        "\n",
        "              # Apply mutation on the offspring\n",
        "              for mutant in offspring:\n",
        "                if random.random() < MUTPB:\n",
        "                  toolbox.mutate(mutant)\n",
        "                  del mutant.fitness.values\n",
        "\n",
        "              # Evaluate the individuals with an invalid fitness\n",
        "              invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "              fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "              for ind, fit in zip(invalid_ind, fitnesses):\n",
        "                ind.fitness.values = fit\n",
        "\n",
        "              # The population is entirely replaced by the offspring\n",
        "              pop[:] = offspring\n",
        "              hall_of_fame.update(pop)\n",
        "              print(\n",
        "                \"HALL OF FAME:\\n\"\n",
        "                + \"\\n\".join(\n",
        "                  [\n",
        "                    f\"  {_}: {ind}, Fitness: {ind.fitness.values[0]}\"\n",
        "                    for _, ind in enumerate(hall_of_fame)\n",
        "                  ]\n",
        "                )\n",
        "              )\n",
        "\n",
        "              fitnesses = [\n",
        "                ind.fitness.values[0] for ind in pop if not np.isinf(ind.fitness.values[0])\n",
        "              ]\n",
        "              mean[g] = np.mean(fitnesses)\n",
        "              best[g] = np.max(fitnesses)\n",
        "\n",
        "            end_t = time.perf_counter()\n",
        "            print(f\"Time Elapsed: {end_t - t:,.2f}\")\n",
        "\n",
        "            # 최적의 파라미터 값 출력\n",
        "            OPTIMISED_STRATEGY_PARAMS = {\n",
        "              k: v for k, v in zip(PARAM_NAMES, hall_of_fame[0])}\n",
        "            STC_params = list(OPTIMISED_STRATEGY_PARAMS.values())\n",
        "            print('**STC 파라미터 값: ', STC_params)\n",
        "\n",
        "            \n",
        "\n",
        "        except:\n",
        "            STC_params = [14, 3, 3, 80, 20]\n",
        "\n",
        "\n",
        "        # 데이터 불러와서 가공 ------------------------------------------------------------\n",
        "        #df = pd.read_json(json_data[fullcode_list0[j]], orient ='index') \n",
        "        #read_df = df.transpose()\n",
        "        \n",
        "        \n",
        "        read_df = pd.read_csv(f)\n",
        "        read_df[\"GDC_sig\"] = \"\"\n",
        "        read_df[\"RSI_sig\"] = \"\"\n",
        "        read_df[\"ROC_sig\"] = \"\"\n",
        "        read_df[\"STC_sig\"] = \"\"\n",
        "        read_df[\"MAP_sig\"] = \"\"\n",
        "\n",
        "        read_df['TDD_CLSPRC'] = read_df['TDD_CLSPRC'].str.replace(',','').astype('float')\n",
        "        read_df['TDD_HGPRC'] = read_df['TDD_HGPRC'].str.replace(',','').astype('float')\n",
        "        read_df['TDD_LWPRC'] = read_df['TDD_LWPRC'].str.replace(',','').astype('float')\n",
        "        read_df['pfast'] = talib.MA(read_df['TDD_CLSPRC'], timeperiod = GDC_params[0], matype=0)\n",
        "        read_df['pslow'] = talib.MA(read_df['TDD_CLSPRC'], timeperiod = GDC_params[1], matype=0)\n",
        "        read_df['RSI'] = talib.RSI(read_df['TDD_CLSPRC'], timeperiod = RSI_params[0])\n",
        "        read_df['ROC'] = talib.ROC(read_df['TDD_CLSPRC'], timeperiod = ROC_params[0]) \n",
        "        read_df['slowk'], read_df['slowd'] = talib.STOCH(read_df['TDD_HGPRC'], read_df['TDD_LWPRC'], read_df['TDD_CLSPRC'], fastk_period = STC_params[0], slowk_period = STC_params[1], slowd_period = STC_params[2], slowk_matype=0, slowd_matype=0)\n",
        "        read_df['MA'] = talib.MA(read_df['TDD_CLSPRC'], timeperiod = MAP_params[0])\n",
        "        ul = []\n",
        "        ll = []\n",
        "        for i in read_df['MA']:\n",
        "            uls = i + (MAP_params[1] * i)\n",
        "            lls = i - (MAP_params[2] * i)\n",
        "            ul.append(uls)\n",
        "            ll.append(lls)\n",
        "\n",
        "        read_df['ul'] = ul\n",
        "        read_df['ll'] = ll\n",
        "\n",
        "        # 매도, 매수 전략 설정 후 GDC_sig 열 추가\n",
        "        first_cross = 0 \n",
        "        for i in range(0, len(read_df)):\n",
        "            if read_df['pfast'][i] < read_df['pslow'][i] and first_cross == 0:\n",
        "              # print('Death cross on day', df['TRD_DD'][i], ':expect the price to continue to fall (매도)')\n",
        "              read_df['GDC_sig'][i] = 1\n",
        "              first_cross=1\n",
        "            elif read_df['pfast'][i] > read_df['pslow'][i] and first_cross ==1:\n",
        "              # print('Golden cross on day', df['TRD_DD'][i], ':expect the price to continue to rise (매수)')\n",
        "              first_cross=0\n",
        "              read_df['GDC_sig'][i] = -1\n",
        "            else:\n",
        "              read_df['GDC_sig'][i] = 0\n",
        "\n",
        "        # 매도 매수 전략 설정 후 RSI_sig 열 추가\n",
        "        for i in range(0, len(read_df)):\n",
        "            if read_df['RSI'][i] < 30: # 30보다 작으면 매수시점\n",
        "                read_df['RSI_sig'][i] = -1\n",
        "            elif read_df['RSI'][i] >= 70: # 70보다 크면 매도시점\n",
        "                read_df['RSI_sig'][i] = 1\n",
        "            else:\n",
        "                read_df['RSI_sig'][i] = 0\n",
        "\n",
        "        # 매도 매수 전략 설정 후 ROC_sig 열 추가\n",
        "        for i in range(0, len(read_df)):\n",
        "            if read_df['ROC'][i] < 0: # 30보다 작으면 매도시점\n",
        "                read_df['ROC_sig'][i] = 1\n",
        "            elif read_df['ROC'][i] >= 0: # 70보다 크면 매수시점\n",
        "                read_df['ROC_sig'][i] = -1\n",
        "            else:\n",
        "                read_df['ROC_sig'][i] = 0      \n",
        "\n",
        "        # 매도 매수 전략 설정 후 MAP_sig 열 추가\n",
        "        for i in range(0, len(read_df)):\n",
        "            if read_df['TDD_CLSPRC'][i] > read_df['ul'][i]: # 매도\n",
        "              read_df['MAP_sig'][i] = 1\n",
        "            elif read_df['TDD_CLSPRC'][i] < read_df['ll'][i]: # 매수\n",
        "              read_df['MAP_sig'][i] = -1\n",
        "            else:\n",
        "              read_df['MAP_sig'][i] = 0\n",
        "\n",
        "        # 매도 매수 전략 설정 후 STC_sig 열 추가\n",
        "        for i in range(0, len(read_df)):\n",
        "            if read_df['slowk'][i] < read_df['slowd'][i] and read_df['slowd'][i] < STC_params[4]:\n",
        "              read_df['STC_sig'][i] = -1\n",
        "            elif read_df['slowk'][i] > read_df['slowd'][i] and read_df['slowd'][i] > STC_params[3]:\n",
        "              read_df['STC_sig'][i] = 1\n",
        "            else:\n",
        "              read_df['STC_sig'][i] = 0\n",
        "\n",
        "        # result = read_df.drop(['pfast', 'pslow', 'RSI'], axis='columns')\n",
        "        result = read_df[['TRD_DD','MKTCAP', 'GDC_sig', 'RSI_sig', 'ROC_sig', 'MAP_sig', 'STC_sig']]        \n",
        "        print(result)\n",
        "\n",
        "        # 조건에 해당하는 날짜 추출.\n",
        "        def get_point(result):\n",
        "          x = list(result['x1'])+ list(result['x2'])\n",
        "          x = list(set(x))\n",
        "          x.sort()\n",
        "          return x\n",
        "\n",
        "        # 전체 df에서 해당 날짜만 가져오기\n",
        "        def get_date(date_list):\n",
        "            global scode1\n",
        "  \n",
        "            if(len(date_list)==0):   #아예 조건에 해당하는 점이 없을 경우\n",
        "                return pd.DataFrame() \n",
        "    \n",
        "            check_df =  scode1[scode1.x == date_list[0]]\n",
        "\n",
        "            for i in date_list :\n",
        "                df = scode1[scode1.x == i]\n",
        "                check_df = check_df.append(df,ignore_index = True)\n",
        "\n",
        "            check_df = check_df.iloc[1:,:]\n",
        "            return check_df\n",
        "\n",
        "\n",
        "        # 두 점 사이 관계 df \n",
        "        def two_point (check_df):\n",
        "\n",
        "            df = check_df[['x']]\n",
        "            df = df.iloc[:-1]\n",
        "\n",
        "            df['x2']= np.nan\n",
        "            df['y1']= np.nan\n",
        "            df['y2']= np.nan\n",
        "            df['t']= np.nan\n",
        "            df['p']= np.nan\n",
        "            df['m']= np.nan\n",
        "            \n",
        "            df.rename(columns ={'x':'x1'}, inplace = True)\n",
        "\n",
        "            for i in range(len(df)): \n",
        "                df.iloc[i,1] = check_df.iloc[i+1,0]\n",
        "                df.iloc[i,2] = check_df.iloc[i,1]\n",
        "                df.iloc[i,3] = check_df.iloc[i+1,1]\n",
        "\n",
        "            for i in range(df.shape[0]):\n",
        "\n",
        "                t = df.iloc[i,1] - df.iloc[i,0]\n",
        "                df.iloc[i,4] = t.days\n",
        "\n",
        "                y1 = df.iloc[i,2]\n",
        "                y2 = df.iloc[i,3]\n",
        "                result = (abs(y2 - y1 )) / ((y1+y2)/2 )\n",
        "                df.iloc[i,5] = result\n",
        "\n",
        "                m = df.iloc[i,3]- df.iloc[i,2]  \n",
        "                if (m>0):\n",
        "                    df.iloc[i,6] = 1\n",
        "                elif (m<0):\n",
        "                    df.iloc[i,6] = -1\n",
        "                else :\n",
        "                    df.iloc[i,6] = 0\n",
        "\n",
        "            return df\n",
        "\n",
        "\n",
        "        # 조건 필터링 \n",
        "        def p_t(df):\n",
        "            t = df['t'] <5\n",
        "            p = df['p']<0.05\n",
        "\n",
        "            result = df[~t&~p]\n",
        "            return result\n",
        "\n",
        "        \n",
        "        \n",
        "        scode = result.copy()\n",
        "        \n",
        "        #시간 순 재정렬.\n",
        "        scode2 = scode.sort_values(by=['TRD_DD'])\n",
        "        scode2.reset_index(drop=True,inplace=True)\n",
        "        scode2['TRD_DD']=pd.to_datetime(scode2['TRD_DD']) #datetime변환\n",
        "\n",
        "        #시가총액 str->float 데이터타입변환\n",
        "        scode2['MKTCAP'] = scode2['MKTCAP'].str.replace(',','').astype('float')\n",
        "\n",
        "        #날짜, 시가총액 열만 추출\n",
        "        scode1 = scode2[['TRD_DD','MKTCAP']]\n",
        "        scode1 = scode1.rename(columns = {'TRD_DD':'x','MKTCAP':'y'})\n",
        "        scode1.reset_index(drop=True,inplace=True)\n",
        "\n",
        "\n",
        "        #기울기 변하는 지점 찾아주기\n",
        "        ischange = list()\n",
        "\n",
        "        for i in range(1,len(scode1)-2):\n",
        "            m1 = scode1.iloc[i,1] - scode1.iloc[i-1,1]\n",
        "            m2 = scode1.iloc[i+1,1] - scode1.iloc[i,1]\n",
        "\n",
        "            if(m1*m2<=0):\n",
        "                ischange.append(scode1.iloc[i,0])\n",
        "\n",
        "        # 전체 df에서 기울기 변하는 지점들만 추출한 후 , (t=5, p=0.05) 에 해당하는 날짜  추출.\n",
        "\n",
        "        check_df = get_date(ischange) #전체 df에서 기울기 변하는 날짜만 추출하기.\n",
        "        if(len(check_df)==0):\n",
        "\n",
        "            scode['TREND']= np.nan\n",
        "            result_js = scode.to_json(orient = 'columns')\n",
        "\n",
        "            result_dict[j] = result_js\n",
        "            print(\"\\n기울기 변하는 날짜가 존재 하지 않음. 조건 성립 X\")\n",
        "            print(\"-----------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "            continue\n",
        "        df = two_point(check_df)\n",
        "        result = p_t(df)   # (t=5, p=0.05) 에 해당하는 날짜  추출.\n",
        "\n",
        "\n",
        "\n",
        "        # 조건에 해당하는 날짜들끼리 다시 (t=5, p=0.05) 에 해당하는 날짜  추출. \n",
        "        red_x = get_point(result)\n",
        "        red = get_date(red_x)\n",
        "\n",
        "        if(len(red)==0): #아예 trend 점 안만들어지는 종목 에러 방지.\n",
        "            scode['TREND']= np.nan\n",
        "            result_js = scode.to_json(orient = 'columns')\n",
        "\n",
        "            result_dict[j] = result_js\n",
        "            print(\"조건에 해당하는 점이 아예 없음.\")\n",
        "            print(\"\\n-----------------------------------------------------------------------------------------\")\n",
        "            continue\n",
        "\n",
        "        df1=two_point(red)\n",
        "        result2=p_t(df1)\n",
        "\n",
        "\n",
        "        #점들이 모두 이어지고, 기울기가 계속 변하는 모습 나올때까지 반복 작업.\n",
        "        while True:\n",
        "\n",
        "            count = 0     \n",
        "            red_x1 = get_point(result2) #조건에 만족하는 날짜 추출\n",
        "\n",
        "            for i in range(result2.shape[0]-1):\n",
        "                a = result2.iloc[i,1] == result2.iloc[i+1,0]\n",
        "                b = result2.iloc[i,6]* result2.iloc[i+1,6]== -1\n",
        "\n",
        "                if(a&b ) :\n",
        "                    count+=1\n",
        "\n",
        "            if (count ==  result2.shape[0]-1 ):\n",
        "                print(\"조건 성립 완료 \\n\")\n",
        "                break\n",
        "\n",
        "            for i in range(result2.shape[0]-1):\n",
        "\n",
        "               #i번째 기울기 음수일때\n",
        "              if (result2.iloc[i,6]== -1):  \n",
        "                #i+1번째 기울기 양수일 때\n",
        "                if (result2.iloc[i+1,6] == 1): \n",
        "                  #점이 이어져 있지 않으면\n",
        "                  if (result2.iloc[i,1] != result2.iloc[i+1,0]):\n",
        "                    if(result2.iloc[i,3]> result2.iloc[i+1,2]):\n",
        "                       red_x1.remove(result2.iloc[i,1])\n",
        "                    else :\n",
        "                      red_x1.remove(result2.iloc[i+1,0]) \n",
        "\n",
        "                #i+1번째 기울기 음수일 때\n",
        "                elif (result2.iloc [i+1,6]== -1):       \n",
        "                   red_x1.remove(result2.iloc[i,1])\n",
        "\n",
        "\n",
        "              #i번째 기울기 양수일때\n",
        "              else :   \n",
        "                #i+1번째 기울기 양수일 때\n",
        "                if (result2.iloc[i+1,6] == 1): \n",
        "                  #점이 이어져 있지 않으면\n",
        "                  if (result2.iloc[i,1] != result2.iloc[i+1,0]):\n",
        "                    red_x1.remove(result2.iloc[i,1])\n",
        "                    red_x1.remove(result2.iloc[i+1,0]) \n",
        "                  #점이 이어져 있으면\n",
        "                  else :\n",
        "                    red_x1.remove(result2.iloc[i,1])\n",
        "                #i+1번째 기울기 음수일 때\n",
        "                else :\n",
        "                  #점이 이어져 있지 않으면\n",
        "                  if (result2.iloc[i,1] != result2.iloc[i+1,0]):\n",
        "                    if (result2.iloc[i,3]>=result2.iloc[i+1,2]):\n",
        "                       red_x1.remove(result2.iloc[i+1,0])\n",
        "                    else:\n",
        "                      red_x1.remove(result2.iloc[i,1])\n",
        "\n",
        "            final = get_date(red_x1)\n",
        "            df1=two_point(final)\n",
        "            result2=p_t(df1)\n",
        "\n",
        "\n",
        "\n",
        "        # trend -1~1 사이 값으로 변환.\n",
        "\n",
        "        final = get_date(red_x1) #최종 기울기 변하는 점 추출.\n",
        "\n",
        "        for k in range(final.shape[0]-1): #기울기 변하는 곳 1, -1로 값 채워주기\n",
        "            if(result2.iloc[k,6]== 1):\n",
        "                final.iloc[k,1] = -1\n",
        "            else :\n",
        "                final.iloc[k,1] = 1\n",
        "\n",
        "        # 마지막 끝 점 (-1,1)해당하는 값으로 채워주기\n",
        "        n = final.shape[0]-2\n",
        "        if(final.iloc[n,1]== -1):\n",
        "            final.iloc[final.shape[0]-1,1] = 1\n",
        "        else:\n",
        "            final.iloc[final.shape[0]-1,1] = -1\n",
        "\n",
        "        # -1~ 1 사이 점 채워주기.(linear interpolation)\n",
        "        scode_trend = scode1[['x']]\n",
        "        scode_trend['TREND'] = np.nan\n",
        "\n",
        "        for i in range(len(final)):\n",
        "            scode_trend.loc[scode_trend['x']== final.iloc[i,0],'TREND'] = final.iloc[i,1]\n",
        "\n",
        "        scode_trend =  scode_trend.set_index('x')\n",
        "        scode_trend = scode_trend[final.iloc[0,0]:final.iloc[len(final)-1,0]].interpolate(method = \"time\")\n",
        "\n",
        "\n",
        "        # 마지막으로 원래 데이터에 TREND 열 만들어주어서 합치기.\n",
        "\n",
        "        scode_trend.reset_index(inplace=True)\n",
        "        scode_trend = scode_trend.rename(columns = {'x':'TRD_DD'})\n",
        "        scode['TRD_DD']=pd.to_datetime(scode['TRD_DD'])\n",
        "        scode = pd.merge(scode, scode_trend, on='TRD_DD', how='left')\n",
        "        scode['TRD_DD'] = scode['TRD_DD'].astype(str).str.replace('-','/') \n",
        "        \n",
        "        scode= scode[['TRD_DD', 'GDC_sig', 'RSI_sig', 'ROC_sig', 'MAP_sig', 'STC_sig','TREND']]\n",
        "        print(scode)\n",
        "\n",
        "        output_path = os.path.join('/opt/ml/processing/processed_data' , code)\n",
        "        #output_path = os.path.join('/opt/ml/processing/processed_data' , f)\n",
        "        pd.DataFrame(scode).to_csv(output_path, index=False)\n",
        "        print('Saving train data {}'.format(output_path))\n",
        "    \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fbade73",
      "metadata": {
        "scrolled": false,
        "id": "7fbade73",
        "outputId": "bc6a4a73-7bc1-458a-dc1a-aa4c3000eea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Job Name:  sagemaker-scikit-learn-2022-01-11-06-19-31-127\n",
            "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-kproject/data/', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-ap-northeast-2-268367265700/sagemaker-scikit-learn-2022-01-11-06-19-31-127/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
            "Outputs:  [{'OutputName': 'output-1', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-kproject/processed_data/', 'LocalPath': '/opt/ml/processing/processed_data', 'S3UploadMode': 'EndOfJob'}}]\n",
            ".............................\u001b[34mCollecting talib-binary\n",
            "  Downloading talib_binary-0.4.19-cp37-cp37m-manylinux1_x86_64.whl (2.4 MB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: numpy in /miniconda3/lib/python3.7/site-packages (from talib-binary) (1.19.5)\u001b[0m\n",
            "\u001b[34mInstalling collected packages: talib-binary\u001b[0m\n",
            "\u001b[34mSuccessfully installed talib-binary-0.4.19\u001b[0m\n",
            "\u001b[34mCollecting seaborn\n",
            "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: numpy>=1.15 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.19.5)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: scipy>=1.0 in /miniconda3/lib/python3.7/site-packages (from seaborn) (1.7.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pandas>=0.23 in /miniconda3/lib/python3.7/site-packages (from seaborn) (0.25.3)\u001b[0m\n",
            "\u001b[34mCollecting matplotlib>=2.2\n",
            "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\u001b[0m\n",
            "\u001b[34mCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\u001b[0m\n",
            "\u001b[34mCollecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\u001b[0m\n",
            "\u001b[34mCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.28.5-py3-none-any.whl (890 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: python-dateutil>=2.7 in /miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\u001b[0m\n",
            "\u001b[34mCollecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.0.6-py3-none-any.whl (97 kB)\u001b[0m\n",
            "\u001b[34mCollecting packaging>=20.0\n",
            "  Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
            "\u001b[34mCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2021.3)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\u001b[0m\n",
            "\u001b[34mInstalling collected packages: pyparsing, pillow, packaging, kiwisolver, fonttools, cycler, matplotlib, seaborn\u001b[0m\n",
            "\u001b[34mSuccessfully installed cycler-0.11.0 fonttools-4.28.5 kiwisolver-1.3.2 matplotlib-3.5.1 packaging-21.3 pillow-9.0.0 pyparsing-3.0.6 seaborn-0.11.2\u001b[0m\n",
            "\u001b[34mCollecting backtrader\n",
            "  Downloading backtrader-1.9.76.123-py2.py3-none-any.whl (410 kB)\u001b[0m\n",
            "\u001b[34mInstalling collected packages: backtrader\u001b[0m\n",
            "\u001b[34mSuccessfully installed backtrader-1.9.76.123\u001b[0m\n",
            "\u001b[34mCollecting backtesting\u001b[0m\n",
            "\u001b[34m  Downloading Backtesting-0.3.3.tar.gz (175 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: numpy>=1.17.0 in /miniconda3/lib/python3.7/site-packages (from backtesting) (1.19.5)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pandas!=0.25.0,>=0.25.0 in /miniconda3/lib/python3.7/site-packages (from backtesting) (0.25.3)\u001b[0m\n",
            "\u001b[34mCollecting bokeh>=1.4.0\n",
            "  Downloading bokeh-2.4.2-py3-none-any.whl (18.5 MB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: typing-extensions>=3.10.0 in /miniconda3/lib/python3.7/site-packages (from bokeh>=1.4.0->backtesting) (3.10.0.2)\u001b[0m\n",
            "\u001b[34mCollecting PyYAML>=3.10\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pillow>=7.1.0 in /miniconda3/lib/python3.7/site-packages (from bokeh>=1.4.0->backtesting) (9.0.0)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: Jinja2>=2.9 in /miniconda3/lib/python3.7/site-packages (from bokeh>=1.4.0->backtesting) (3.0.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: packaging>=16.8 in /miniconda3/lib/python3.7/site-packages (from bokeh>=1.4.0->backtesting) (21.3)\u001b[0m\n",
            "\u001b[34mCollecting tornado>=5.1\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /miniconda3/lib/python3.7/site-packages (from Jinja2>=2.9->bokeh>=1.4.0->backtesting) (2.0.1)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /miniconda3/lib/python3.7/site-packages (from packaging>=16.8->bokeh>=1.4.0->backtesting) (3.0.6)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: python-dateutil>=2.6.1 in /miniconda3/lib/python3.7/site-packages (from pandas!=0.25.0,>=0.25.0->backtesting) (2.8.2)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /miniconda3/lib/python3.7/site-packages (from pandas!=0.25.0,>=0.25.0->backtesting) (2021.3)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: six>=1.5 in /miniconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas!=0.25.0,>=0.25.0->backtesting) (1.16.0)\u001b[0m\n",
            "\u001b[34mBuilding wheels for collected packages: backtesting\n",
            "  Building wheel for backtesting (setup.py): started\n",
            "  Building wheel for backtesting (setup.py): finished with status 'done'\n",
            "  Created wheel for backtesting: filename=Backtesting-0.3.3-py3-none-any.whl size=173823 sha256=1473866cc72dc1dc979270c054034c6336ecb9c942e14843410c37fd23801d81\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/1d/ea/65dacebc37da7655d8a1fd0f315ac39d102e31d6545237a1c6\u001b[0m\n",
            "\u001b[34mSuccessfully built backtesting\u001b[0m\n",
            "\u001b[34mInstalling collected packages: tornado, PyYAML, bokeh, backtesting\u001b[0m\n",
            "\u001b[34mSuccessfully installed PyYAML-6.0 backtesting-0.3.3 bokeh-2.4.2 tornado-6.1\u001b[0m\n",
            "\u001b[34mCollecting deap\n",
            "  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: numpy in /miniconda3/lib/python3.7/site-packages (from deap) (1.19.5)\u001b[0m\n",
            "\u001b[34mInstalling collected packages: deap\u001b[0m\n",
            "\u001b[34mSuccessfully installed deap-1.3.1\u001b[0m\n",
            "\u001b[34mCollecting IPython\n",
            "  Downloading ipython-7.31.0-py3-none-any.whl (792 kB)\u001b[0m\n",
            "\u001b[34mRequirement already satisfied: setuptools>=18.5 in /miniconda3/lib/python3.7/site-packages (from IPython) (58.0.4)\u001b[0m\n",
            "\u001b[34mCollecting pygments\n",
            "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\u001b[0m\n",
            "\u001b[34mCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.24-py3-none-any.whl (374 kB)\u001b[0m\n",
            "\u001b[34mCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\u001b[0m\n",
            "\u001b[34mCollecting traitlets>=4.2\n",
            "  Downloading traitlets-5.1.1-py3-none-any.whl (102 kB)\u001b[0m\n",
            "\u001b[34mCollecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\u001b[0m\n",
            "\u001b[34mCollecting jedi>=0.16\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\u001b[0m\n",
            "\u001b[34mCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\u001b[0m\n",
            "\u001b[34mCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\u001b[0m\n",
            "\u001b[34mCollecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
            "\u001b[34mCollecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\u001b[0m\n",
            "\u001b[34mCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
            "\u001b[34mCollecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\u001b[0m\n",
            "\u001b[34mInstalling collected packages: wcwidth, traitlets, ptyprocess, parso, pygments, prompt-toolkit, pickleshare, pexpect, matplotlib-inline, jedi, decorator, backcall, IPython\u001b[0m\n",
            "\u001b[34mSuccessfully installed IPython-7.31.0 backcall-0.2.0 decorator-5.1.1 jedi-0.18.1 matplotlib-inline-0.1.3 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.24 ptyprocess-0.7.0 pygments-2.11.2 traitlets-5.1.1 wcwidth-0.2.5\u001b[0m\n",
            "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
            "  import imp\u001b[0m\n",
            "\u001b[34mReceived arguments Namespace()\u001b[0m\n",
            "\u001b[34m각 인스턴스 처리하는 파일 개수 :  100\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:201: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
            "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_bt['TRD_DD'] = pd.to_datetime(df_bt['TRD_DD'])\u001b[0m\n",
            "\u001b[34m/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py:4238: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().rename(**kwargs)\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:206: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
            "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_bt['Open'] = df_bt['Open'].str.replace(',','').astype('float')\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:207: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
            "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_bt['High'] = df_bt['High'].str.replace(',','').astype('float')\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:208: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
            "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_bt['Low'] = df_bt['Low'].str.replace(',','').astype('float')\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:209: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
            "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_bt['Close'] = df_bt['Close'].str.replace(',','').astype('float')\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:210: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame.\u001b[0m\n",
            "\u001b[34mTry using .loc[row_indexer,col_indexer] = value instead\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_bt['Volume'] = df_bt['Volume'].str.replace(',','').astype('float')\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [75, 203], Fitness: -2.5458880408e-05\n",
            "  1: [50, 236], Fitness: -1.9936904681e-05\n",
            "  2: [39, 242], Fitness: -1.762196825e-05\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [99, 164], Fitness: -0.000699080708868\n",
            "  1: [75, 203], Fitness: -2.5458880408e-05\n",
            "  2: [50, 236], Fitness: -1.9936904681e-05\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [99, 164], Fitness: -0.000699080708868\n",
            "  1: [86, 191], Fitness: -3.8035612744e-05\n",
            "  2: [75, 203], Fitness: -2.5458880408e-05\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [99, 164], Fitness: -0.000699080708868\n",
            "  1: [86, 191], Fitness: -3.8035612744e-05\n",
            "  2: [75, 203], Fitness: -2.5458880408e-05\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [99, 164], Fitness: -0.000699080708868\n",
            "  1: [86, 191], Fitness: -3.8035612744e-05\n",
            "  2: [75, 203], Fitness: -2.5458880408e-05\u001b[0m\n",
            "\u001b[34mTime Elapsed: 399.95\u001b[0m\n",
            "\u001b[34m**GDC 파라미터 값:  [99, 164]\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0/5 [00:00<?, ?it/s]#015 20%|██        | 1/5 [01:52<07:29, 112.31s/it]#015 40%|████      | 2/5 [03:02<04:23, 87.82s/it] #015 60%|██████    | 3/5 [04:12<02:38, 79.35s/it]#015 80%|████████  | 4/5 [05:31<01:19, 79.25s/it]#015100%|██████████| 5/5 [06:39<00:00, 75.41s/it]#015100%|██████████| 5/5 [06:39<00:00, 79.99s/it]\u001b[0m\n",
            "\u001b[34m/miniconda3/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'FitnessMin' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\u001b[0m\n",
            "\u001b[34m/miniconda3/lib/python3.7/site-packages/deap/creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  RuntimeWarning)\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [4], Fitness: -0.005047318611987\n",
            "  1: [36], Fitness: -0.001794204718758\n",
            "  2: [34], Fitness: -0.000691981662486\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [4], Fitness: -0.005047318611987\n",
            "  1: [36], Fitness: -0.001794204718758\n",
            "  2: [34], Fitness: -0.000691981662486\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [4], Fitness: -0.005047318611987\n",
            "  1: [36], Fitness: -0.001794204718758\n",
            "  2: [34], Fitness: -0.000691981662486\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [4], Fitness: -0.005047318611987\n",
            "  1: [36], Fitness: -0.001794204718758\n",
            "  2: [34], Fitness: -0.000691981662486\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [4], Fitness: -0.005047318611987\n",
            "  1: [36], Fitness: -0.001794204718758\n",
            "  2: [34], Fitness: -0.000691981662486\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0/5 [00:00<?, ?it/s]#015 20%|██        | 1/5 [01:39<06:39, 99.94s/it]#015 40%|████      | 2/5 [02:46<04:00, 80.18s/it]#015 60%|██████    | 3/5 [03:55<02:30, 75.18s/it]#015 80%|████████  | 4/5 [05:10<01:15, 75.26s/it]#015100%|██████████| 5/5 [06:28<00:00, 76.08s/it]#015100%|██████████| 5/5 [06:28<00:00, 77.69s/it]\u001b[0m\n",
            "\u001b[34mTime Elapsed: 388.43\u001b[0m\n",
            "\u001b[34mRSI 파라미터 값:  [4]\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [100], Fitness: -0.001081212579909\n",
            "  1: [69], Fitness: -0.000494281777685\n",
            "  2: [67], Fitness: -0.000351091235446\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [136], Fitness: -0.001548736811538\n",
            "  1: [100], Fitness: -0.001081212579909\n",
            "  2: [69], Fitness: -0.000494281777685\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [136], Fitness: -0.001548736811538\n",
            "  1: [100], Fitness: -0.001081212579909\n",
            "  2: [69], Fitness: -0.000494281777685\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [136], Fitness: -0.001548736811538\n",
            "  1: [100], Fitness: -0.001081212579909\n",
            "  2: [69], Fitness: -0.000494281777685\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [136], Fitness: -0.001548736811538\n",
            "  1: [100], Fitness: -0.001081212579909\n",
            "  2: [69], Fitness: -0.000494281777685\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0/5 [00:00<?, ?it/s]#015 20%|██        | 1/5 [01:53<07:33, 113.28s/it]#015 40%|████      | 2/5 [03:07<04:30, 90.11s/it] #015 60%|██████    | 3/5 [04:15<02:40, 80.27s/it]#015 80%|████████  | 4/5 [05:34<01:19, 79.64s/it]#015100%|██████████| 5/5 [06:53<00:00, 79.57s/it]#015100%|██████████| 5/5 [06:53<00:00, 82.77s/it]\u001b[0m\n",
            "\u001b[34mTime Elapsed: 413.87\u001b[0m\n",
            "\u001b[34m**ROC 파라미터 값:  [136]\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [150, 0.06753722930245548, 8], Fitness: 5.09410324e-07\n",
            "  1: [89, 0.07049191115017378, 0.05793873783843731], Fitness: 7.22635771e-07\n",
            "  2: [68, 0.07078688097685099, 0.05203891440418363], Fitness: 8.0070462e-07\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [150, 0.06753722930245548, 8], Fitness: 5.09410324e-07\n",
            "  1: [142, 0.05307882818821648, 0.0834987632838584], Fitness: 5.22915654e-07\n",
            "  2: [124, 25, 39], Fitness: 6.18777094e-07\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [150, 0.06753722930245548, 8], Fitness: 5.09410324e-07\n",
            "  1: [142, 0.050850102890522955, 0.0834987632838584], Fitness: 5.22915654e-07\n",
            "  2: [142, 0.05307882818821648, 0.0834987632838584], Fitness: 5.22915654e-07\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [150, 0.06753722930245548, 8], Fitness: 5.09410324e-07\n",
            "  1: [142, 0.050850102890522955, 0.0834987632838584], Fitness: 5.22915654e-07\n",
            "  2: [142, 0.05307882818821648, 0.0834987632838584], Fitness: 5.22915654e-07\u001b[0m\n",
            "\u001b[34m HALL OF FAME:\n",
            "  0: [150, 0.06753722930245548, 8], Fitness: 5.09410324e-07\n",
            "  1: [142, 0.050850102890522955, 0.0834987632838584], Fitness: 5.22915654e-07\n",
            "  2: [142, 0.05307882818821648, 0.0834987632838584], Fitness: 5.22915654e-07\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0/5 [00:00<?, ?it/s]#015 20%|██        | 1/5 [01:50<07:20, 110.24s/it]#015 40%|████      | 2/5 [02:56<04:13, 84.42s/it] #015 60%|██████    | 3/5 [04:19<02:47, 83.71s/it]#015 80%|████████  | 4/5 [05:29<01:18, 78.37s/it]#015100%|██████████| 5/5 [06:39<00:00, 75.26s/it]#015100%|██████████| 5/5 [06:39<00:00, 79.87s/it]\u001b[0m\n",
            "\u001b[34mTime Elapsed: 399.38\u001b[0m\n",
            "\u001b[34m**MAP 파라미터 값:  [150, 0.06753722930245548, 8]\u001b[0m\n",
            "\u001b[34m#015  0%|          | 0/5 [00:00<?, ?it/s]#015  0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1033: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['GDC_sig'][i] = 0\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1026: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['GDC_sig'][i] = 1\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1031: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['GDC_sig'][i] = -1\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1042: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['RSI_sig'][i] = 0\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1040: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['RSI_sig'][i] = 1\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1038: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['RSI_sig'][i] = -1\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1051: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['ROC_sig'][i] = 0\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1047: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['ROC_sig'][i] = 1\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1049: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['ROC_sig'][i] = -1\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1060: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['MAP_sig'][i] = 0\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1056: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['MAP_sig'][i] = 1\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1069: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['STC_sig'][i] = 0\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1067: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['STC_sig'][i] = 1\u001b[0m\n",
            "\u001b[34m/opt/ml/processing/input/code/preprocessing.py:1065: SettingWithCopyWarning: \u001b[0m\n",
            "\u001b[34mA value is trying to be set on a copy of a slice from a DataFrame\u001b[0m\n",
            "\u001b[34mSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  read_df['STC_sig'][i] = -1\n",
            "          TRD_DD           MKTCAP GDC_sig RSI_sig ROC_sig MAP_sig STC_sig\u001b[0m\n",
            "\u001b[34m0     2021/12/27  108,565,948,700       0       0       0       0       0\u001b[0m\n",
            "\u001b[34m1     2021/12/24  112,709,687,200       0       0       0       0       0\u001b[0m\n",
            "\u001b[34m2     2021/12/23  111,466,565,650       0       0       0       0       0\u001b[0m\n",
            "\u001b[34m3     2021/12/22  113,952,808,750       0       0       0       0       0\u001b[0m\n",
            "\u001b[34m4     2021/12/21  111,880,939,500       0       0       0       0       0\u001b[0m\n",
            "\u001b[34m...          ...              ...     ...     ...     ...     ...     ...\u001b[0m\n",
            "\u001b[34m5419  2000/01/17   40,140,000,000       0       1      -1       1       0\u001b[0m\n",
            "\u001b[34m5420  2000/01/14   45,540,000,000       0       1      -1       1       0\u001b[0m\n",
            "\u001b[34m5421  2000/01/13   51,750,000,000       0       1      -1       1       0\u001b[0m\n",
            "\u001b[34m5422  2000/01/12   46,260,000,000       0       0      -1       1       0\u001b[0m\n",
            "\u001b[34m5423  2000/01/11   41,310,000,000       0       0      -1       1       0\u001b[0m\n",
            "\u001b[34m[5424 rows x 7 columns]\u001b[0m\n",
            "\u001b[34m조건 성립 완료 \n",
            "          TRD_DD GDC_sig RSI_sig ROC_sig MAP_sig STC_sig     TREND\u001b[0m\n",
            "\u001b[34m0     2021/12/27       0       0       0       0       0       NaN\u001b[0m\n",
            "\u001b[34m1     2021/12/24       0       0       0       0       0       NaN\u001b[0m\n",
            "\u001b[34m2     2021/12/23       0       0       0       0       0       NaN\u001b[0m\n",
            "\u001b[34m3     2021/12/22       0       0       0       0       0       NaN\u001b[0m\n",
            "\u001b[34m4     2021/12/21       0       0       0       0       0       NaN\u001b[0m\n",
            "\u001b[34m...          ...     ...     ...     ...     ...     ...       ...\u001b[0m\n",
            "\u001b[34m5419  2000/01/17       0       1      -1       1       0 -0.142857\u001b[0m\n",
            "\u001b[34m5420  2000/01/14       0       1      -1       1       0  0.714286\u001b[0m\n",
            "\u001b[34m5421  2000/01/13       0       1      -1       1       0  1.000000\u001b[0m\n",
            "\u001b[34m5422  2000/01/12       0       0      -1       1       0       NaN\u001b[0m\n",
            "\u001b[34m5423  2000/01/11       0       0      -1       1       0       NaN\u001b[0m\n",
            "\u001b[34m[5424 rows x 7 columns]\u001b[0m\n",
            "\u001b[34mSaving train data /opt/ml/processing/processed_data/KR7037370004.csv\u001b[0m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sklearn_processor.run(\n",
        "    code=\"preprocessing.py\",\n",
        "    inputs=[ProcessingInput(source='s3://sagemaker-kproject/data/',\n",
        "                             s3_data_distribution_type='ShardedByS3Key',\n",
        "                            destination=\"/opt/ml/processing/input\")],\n",
        "           \n",
        "    outputs=[\n",
        "        ProcessingOutput(source='/opt/ml/processing/processed_data',\n",
        "                         destination = 's3://sagemaker-kproject/processed_data/')\n",
        "        #ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\"),\n",
        "    ]      \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03cf6cf1",
      "metadata": {
        "id": "03cf6cf1",
        "outputId": "1173af2a-7927-4cde-bb98-2728312271c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TRD_DD</th>\n",
              "      <th>GDC_sig</th>\n",
              "      <th>RSI_sig</th>\n",
              "      <th>ROC_sig</th>\n",
              "      <th>MAP_sig</th>\n",
              "      <th>STC_sig</th>\n",
              "      <th>TREND</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021/12/27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021/12/24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021/12/23</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021/12/22</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021/12/21</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5419</th>\n",
              "      <td>2000/01/17</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5420</th>\n",
              "      <td>2000/01/14</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5421</th>\n",
              "      <td>2000/01/13</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5422</th>\n",
              "      <td>2000/01/12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5423</th>\n",
              "      <td>2000/01/11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5424 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          TRD_DD  GDC_sig  RSI_sig  ROC_sig  MAP_sig  STC_sig     TREND\n",
              "0     2021/12/27        0        0        0        0        0       NaN\n",
              "1     2021/12/24        0        0        0        0        0       NaN\n",
              "2     2021/12/23        0        0        0        0        0       NaN\n",
              "3     2021/12/22        0        0        0        0        0       NaN\n",
              "4     2021/12/21        0        0        0        0        0       NaN\n",
              "...          ...      ...      ...      ...      ...      ...       ...\n",
              "5419  2000/01/17        0        1       -1        1        0 -0.142857\n",
              "5420  2000/01/14        0        1       -1        1        0  0.714286\n",
              "5421  2000/01/13        0        1       -1        1        0  1.000000\n",
              "5422  2000/01/12        0        0       -1        1        0       NaN\n",
              "5423  2000/01/11        0        0       -1        1        0       NaN\n",
              "\n",
              "[5424 rows x 7 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed_data = \"s3://sagemaker-kproject/processed_data/KR7037370004.csv\".format(region)\n",
        "processed_data = pd.read_csv(processed_data)\n",
        "processed_data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Custom (custom_python)",
      "language": "python",
      "name": "custom_python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.15"
    },
    "colab": {
      "name": "AWS_processing.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}